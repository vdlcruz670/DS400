---
title: "Test Results"
format: html
editor: visual
---

#### Load Libraries

```{r, message=FALSE}
library(tidyverse)
library(janitor)
library(vembedr)
```

#### The Story

You test positive for a rare disease that only effects 0.001 (One in one thousand people).

So you ask the doctor:

-   How certain is it that I have this disease?

    -   The test correctly identifies 99% of people that have the disease and only incorrectly identifies 1% of people that don't have the disease

What are the chances that you actually have this disease?

-   Some would say 99%, the accuracy of the test

    -   What does bayes say?

$$
P(B \mid A) = \frac{P(B) L(B \mid A)}{P(A)} 
$$

B \<- Has Disease

A \<- Positive test result

P(B\|A) - The probability of having the disease given a positive test result

#### Simulate the Data

```{r}

set.seed(70)  # For reproducibility

# Parameters
n_patients <- 10000  # Total population size
n_diseased <- 10     # Number of patients with the disease
sensitivity <- 0.99  # True positive rate (sensitivity)
false_positive_rate <- 0.01  # False positive rate

# Step 1: Create the DataFrame with patients
patients <- data.frame(
  patient_id = 1:n_patients,
  has_disease = c(rep(1, n_diseased), rep(0, n_patients - n_diseased))  # 10 with the disease, rest without
)

# Shuffle the DataFrame to randomize patient order
patients <- patients %>%
  sample_frac(size = 1)

# Step 2: Simulate the test results based on disease status
patients <- patients %>%
  mutate(
    # Test result is positive if the person has the disease and the test is sensitive,
    # or if they don't have the disease but it's a false positive
    test_result = case_when(
      has_disease == 1 & rbinom(n_patients, size = 1, prob = sensitivity) == 1 ~ "positive",
      has_disease == 0 & rbinom(n_patients, size = 1, prob = false_positive_rate) == 1 ~ "positive",
      TRUE ~ "negative"
    )
  )




```

#### Apply Bayes Theorem in Class

P(B)

```{r}
patients %>% 
  tabyl(has_disease) %>% 
  adorn_totals("row")
```

```{r}
prior_prob_has_disease <- 0.001
```

P(A)

```{r}
patients %>% 
  tabyl(test_result) %>% 
  adorn_totals("row")
```

```{r}
prior_prob_positive <- 0.0112
```

L(B\|A) = P(A\|B)

```{r}
patients %>% 
  tabyl(test_result, has_disease) %>% 
  adorn_percentages("col") 
```

```{r}
likelihood_disease_positive_result <- 1
```

-   P(B\|A) = P(B)LP(B/A) / P(A)

```{r}
(prior_prob_has_disease*likelihood_disease_positive_result) / prior_prob_positive
```

```{r}
patients %>% 
  tabyl(has_disease, test_result) %>% 
  adorn_percentages("col") 
```

#### Video

```{r}
embed_url("https://www.youtube.com/watch?v=R13BD8qKeTg")
```

#### What about two positive test results?

$$
P(\text{have disease} \mid \text{positive second test}) = \frac{P(\text{have disease after first positive}) \cdot P(\text{positive second test} \mid \text{have disease})}{P(\text{positive second test})}
$$

-   I think that every part of the equation has to change considering that we're looking at a new problem. For example, we're trying to find a new P(B\|A), which is the probability that someone has a disease given that they tested positive twice. So A would be that they tested positive twice and B is that they have the disease.

-   We'd get new data, who tested positive twice. With this new data, we'd also get who tested positive the first time and not the second. I think it gets a little confusing when we take into account the probability of people who have a disease after the first positive, considering that they would have the disease the second positive? Or maybe the P(B) would just be the .089 we found earlier.
